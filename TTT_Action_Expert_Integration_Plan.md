# TTT é›†æˆåˆ° Action Expert å®æ–½è®°å½•

## æ¦‚è¿°

æœ¬æ–‡æ¡£è®°å½•äº†å°† Test-Time Training (TTT) layers é›†æˆåˆ° PI0.5 çš„ Action Expert (GemmaForCausalLM) ä¸­çš„å®Œæ•´å®æ–½è¿‡ç¨‹ï¼ŒåŒ…æ‹¬è®¾è®¡å†³ç­–ã€å‚è€ƒå®ç°åˆ†æå’Œå·²å®Œæˆçš„å·¥ä½œã€‚

---

## âœ… å·²å®Œæˆå·¥ä½œ (Phase 1 & 2)

### 1. TTT æ ¸å¿ƒç»„ä»¶å®ç°

#### 1.1 TTTLinear with Batch-Parallel Optimization âœ…
**æ–‡ä»¶**: `/opt/tiger/openpi/src/openpi/models_pytorch/ttt_with_gate.py`

**æ ¸å¿ƒç‰¹æ€§**:
- âœ… **Batch-parallel TTT**: æ‰€æœ‰ tokens åŒæ—¶ä¼˜åŒ–ï¼Œæ—  sequential scan
- âœ… **Non-causal attention**: å»é™¤å› æœæ©ç ï¼Œå…è®¸å…¨å±€ token äº¤äº’ï¼ˆé€‚åˆå»å™ªï¼‰
- âœ… **Learnable input-dependent LR**: `eta = ttt_base_lr * sigmoid(X @ W_lr + b_lr) / head_dim`
- âœ… **Closed-form dual form**: ä¸€æ­¥é—­å¼è§£ï¼Œé«˜æ•ˆè®¡ç®—
- âœ… **Per-dimension learnable gating**: ç±»ä¼¼ ttt-video-dit çš„ SSMGating
- âœ… **Adaptive normalization (å¯é€‰)**: æ”¯æŒ AdaRMS åŠ¨æ€ gateï¼ˆæœªå¯ç”¨ï¼‰

**è®¾è®¡é€‰æ‹©**:
```python
class TTTWithAdaptiveNorm(nn.Module):
    def __init__(
        self,
        num_heads: int,
        hidden_size: int,
        use_dual_form: bool = True,         # ä½¿ç”¨ dual formï¼ˆæ›´é«˜æ•ˆï¼‰
        gating_alpha_init: float = 0.1,    # é™æ€ gate åˆå§‹åŒ–ä¸º 0.1
    ):
        # TTT å‚æ•° (W1, b1)
        self.W1 = nn.Parameter(...)
        self.b1 = nn.Parameter(...)

        # å¯å­¦ä¹ çš„ã€è¾“å…¥ä¾èµ–çš„å­¦ä¹ ç‡å‚æ•°
        self.learnable_ttt_lr_weight = nn.Parameter(...)  # [num_heads, hidden_size, 1]
        self.learnable_ttt_lr_bias = nn.Parameter(...)    # [num_heads, 1]

        # é™æ€å¯å­¦ä¹  gate (tanh(alpha) â‰ˆ 0.1 at start)
        self.gating_alpha = nn.Parameter(torch.ones(hidden_size) * gating_alpha_init)
```

**å…³é”®ä¼˜åŒ–**:
- **ç§»é™¤äº†ä¸å¿…è¦çš„ input normalization**: TTT è¾“å…¥å·²ç»æ˜¯ attention outputï¼Œä¸éœ€è¦å† norm
- **Non-causal**: `Attn1 = XQ @ X1.transpose(-2, -1)` (å»æ‰ `torch.tril`)
- **Learnable eta**: `eta = ttt_base_lr * sigmoid(X @ W_lr + b_lr) / head_dim` [B, num_heads, L, 1]
- **Dual form**: `Z1_bar = XQ @ W1_init - Attn1 @ (eta * grad_l_wrt_Z1) + b1_bar`

#### 1.2 GemmaDecoderLayer é›†æˆ âœ…
**æ–‡ä»¶**: `/opt/tiger/openpi/src/openpi/models_pytorch/transformers_replace/models/gemma/modeling_gemma.py`

**é›†æˆæ¨¡å¼**: **After Attention** (Sequential)
```python
# [1] Attention Block
residual = hidden_states
hidden_states, gate_attn = self.input_layernorm(hidden_states, adarms_cond)
attn_output = self.self_attn(hidden_states, ...)
hidden_states = _gated_residual(residual, attn_output, gate_attn)

# [2] TTT Block (if enabled)
if self.ttt_layer is not None:
    ttt_output, gate_ttt = self.ttt_layer(attn_output, adarms_cond)
    hidden_states = hidden_states + gate_ttt * ttt_output

# [3] MLP Block
residual = hidden_states
hidden_states, gate_mlp = self.post_attention_layernorm(hidden_states, adarms_cond)
hidden_states = self.mlp(hidden_states)
hidden_states = _gated_residual(residual, hidden_states, gate_mlp)
```

**æ”¯æŒçš„é…ç½®**:
- `ttt_layer_positions`: æŒ‡å®šå“ªäº›å±‚ä½¿ç”¨ TTTï¼ˆæ”¯æŒ `"all"` æˆ– `[14, 15, 16, 17]`ï¼‰
- `ttt_layer_type`: `"linear"` (å½“å‰åªæ”¯æŒ linearï¼Œå¯æ‰©å±•åˆ° MLP)
- `use_dual_form`: `True` (ä½¿ç”¨é—­å¼è§£)

#### 1.3 é…ç½®ç³»ç»Ÿ âœ…
**æ–‡ä»¶**:
- `/opt/tiger/openpi/src/openpi/models_pytorch/transformers_replace/models/gemma/configuration_gemma.py`
- `/opt/tiger/openpi/src/openpi/models/pi0_config.py`
- `/opt/tiger/openpi/src/openpi/training/config.py`

**è®­ç»ƒé…ç½®ç¤ºä¾‹**:
```python
TrainConfig(
    name="pi05_simpler_zscore_ttt",
    model=pi0_config.Pi0Config(
        pi05=True,
        discrete_state_input=True,
        use_ttt=True,
        ttt_layer_type="linear",           # Linear TTT with closed-form solution
        ttt_layer_positions="all",          # Apply to all layers
        use_dual_form=True,                 # Use dual form for efficiency
    ),
    ...
)
```

### 2. Git æäº¤å†å²

**Commit 1**: `83cbfde` - Simplify TTT layer to use fixed learning rate with closed-form solution
- ç§»é™¤ learnable LRï¼ˆdual form ä¸éœ€è¦ï¼‰
- æ·»åŠ  `ttt_layer_type="linear"` é…ç½®

**Commit 2**: `180252b` - Add use_dual_form parameter to TTT layer for optimization method selection
- æ·»åŠ  dual form æ”¯æŒ
- æ”¯æŒ `ttt_layer_positions="all"`

**Commit 3**: (æœªæäº¤) - Remove unnecessary input normalization and add learnable gating
- ç§»é™¤ TTT å†…éƒ¨çš„ input norm
- æ·»åŠ é™æ€ learnable `gating_alpha`

**Commit 4**: `[latest]` - Replace fixed eta with learnable input-dependent learning rate (non-causal)
- âœ… æ·»åŠ  `learnable_ttt_lr_weight` å’Œ `learnable_ttt_lr_bias` å‚æ•°
- âœ… ç§»é™¤å› æœæ©ç  `torch.tril`ï¼ˆnon-causal denoisingï¼‰
- âœ… è®¡ç®—è¾“å…¥ä¾èµ–çš„ `eta = ttt_base_lr * sigmoid(X @ W_lr + b_lr) / head_dim`
- âœ… åªä½¿ç”¨ `ttt_lr_eta`ï¼Œä¸ä½¿ç”¨ `token_eta`ï¼ˆæ‰€æœ‰ token å¹³ç­‰å¯¹å¾…ï¼‰

---

## ğŸ“Š å‚è€ƒå®ç°åˆ†æ: ttt-video-dit

æˆ‘ä»¬è¯¦ç»†åˆ†æäº† `/opt/tiger/openpi/ttt-video-dit` é¡¹ç›®ï¼Œè¯†åˆ«å‡ºä»¥ä¸‹å…³é”®æŠ€æœ¯ï¼š

### å·²å®ç°çš„æŠ€æœ¯ âœ…

| æŠ€æœ¯ | ttt-video-dit | OpenPI | çŠ¶æ€ |
|------|---------------|--------|------|
| **Batch-parallel optimization** | âŒ (uses sequential scan) | âœ… | å·²å®ç° |
| **Closed-form dual form** | âœ… | âœ… | å·²å®ç° |
| **Learnable static gating (SSMGating)** | âœ… | âœ… | å·²å®ç° |
| **AdaRMS/AdaLN dynamic gating** | âœ… (AdaLN) | âœ… (AdaRMS) | å·²å®ç° |

### å€¼å¾—å€Ÿé‰´çš„æŠ€æœ¯ ğŸ”„

#### é«˜ä¼˜å…ˆçº§ (å»ºè®®å®ç°)

1. **TTTMLP Variant** â­â­â­
   ```python
   class TTTMLP(TTTBase):
       def __init__(self, config):
           self.W1 = nn.Parameter(torch.normal(0, 0.02, size=(num_heads, head_dim, 4*head_dim)))
           self.b1 = nn.Parameter(torch.zeros(num_heads, 1, 4*head_dim))
           self.W2 = nn.Parameter(torch.normal(0, 0.02, size=(num_heads, 4*head_dim, head_dim)))
           self.b2 = nn.Parameter(torch.zeros(num_heads, 1, head_dim))
   ```
   - æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼ˆ2-layer MLP vs linearï¼‰
   - å®¹æ˜“å®ç°ï¼ˆåªéœ€æ‰©å±•å½“å‰ TTTLinearï¼‰
   - å¯èƒ½æ˜¾è‘—æå‡å»å™ªè´¨é‡

2. **`@torch.compile` Decorators** â­â­â­
   ```python
   @torch.compile
   def ttt_batch_parallel(self, XQ, XK, XV):
       # ... existing code ...
   ```
   - é›¶æˆæœ¬çš„ 10-30% åŠ é€Ÿ
   - åªéœ€åŠ è£…é¥°å™¨

3. **Reconstruction Target Normalization** â­â­
   ```python
   reconstruction_target = XV - XK
   # Add LayerNorm
   mean = reconstruction_target.mean(dim=-1, keepdim=True)
   std = reconstruction_target.std(dim=-1, keepdim=True)
   reconstruction_target = (reconstruction_target - mean) / (std + eps)
   reconstruction_target = self.ttt_norm_weight * reconstruction_target + self.ttt_norm_bias
   ```
   - ç¨³å®šè®­ç»ƒ
   - å¤„ç†ä¸åŒå°ºåº¦çš„åŠ¨ä½œ

#### ä¸­ä¼˜å…ˆçº§ (å€¼å¾—å®éªŒ)

4. **Bidirectional TTT** â­â­â­
   ```python
   # Forward pass
   emb = forward_ssm(emb, seq_metadata)
   emb = residual + forward_gate(emb)

   # Reverse pass (same parameters, different input order)
   emb = torch.flip(emb, dims=[1])
   emb = reverse_ssm(emb, seq_metadata)
   emb = torch.flip(emb, dims=[1])
   emb = residual + reverse_gate(emb)
   ```
   - æ•è·åŒå‘ä¾èµ–
   - ä½¿ç”¨ç›¸åŒå‚æ•°ï¼ˆparameter efficientï¼‰
   - å¯èƒ½æ˜¾è‘—æå‡è´¨é‡

5. **L2 Normalization on Q/K** â­â­
   ```python
   XQ = F.normalize(XQ, p=2, dim=-1)
   XK = F.normalize(XK, p=2, dim=-1)
   ```
   - è®­ç»ƒç¨³å®šæ€§
   - ä¸€è¡Œä»£ç 

6. **Gradient Checkpointing** â­â­
   - ä¸ºæœªæ¥æ›´é•¿åºåˆ—å‡†å¤‡
   - PyTorch åŸç”Ÿæ”¯æŒ

#### ä½ä¼˜å…ˆçº§ (ä¸æ¨è)

7. **Sequential mini-batch scan** â­
   - ä¸ batch-parallel è®¾è®¡å†²çª
   - **Skip**

8. **Triton/CUDA kernels** â­
   - åºåˆ—å¤ªçŸ­ï¼ˆ256 tokensï¼‰ï¼ŒPyTorch å¤Ÿç”¨
   - **Skip unless bottleneck**

9. **RoPE in TTT** â­
   - ä¸ batch-parallel å†²çª
   - Attention å·²æœ‰ RoPE
   - **Skip**

### Gating æœºåˆ¶å¯¹æ¯”

**ttt-video-dit ä½¿ç”¨åŒå±‚ gating**:
1. **SSMGating (TTT å†…éƒ¨)**: é™æ€å¯å­¦ä¹  `tanh(alpha)`
2. **AdaLN gate (å¤–éƒ¨)**: åŠ¨æ€ timestep-conditioned gate

**OpenPI å½“å‰è®¾è®¡** (ä¸ ttt-video-dit ä¸€è‡´):
1. **Static `gating_alpha`**: `tanh(self.gating_alpha)` [hidden_size]
2. **AdaRMS gate (å¤–éƒ¨)**: Timestep-conditioned gate from `adarms_cond`

**é‡è¦å‘ç°**: âŒ ttt-video-dit çš„ SSMGating **æ²¡æœ‰ cond_dim**ï¼Œæ˜¯çº¯é™æ€å¯å­¦ä¹ çš„ï¼

---

## ğŸ”§ å½“å‰å®ç°ç»†èŠ‚

### TTT Layer æ¶æ„

```python
# Input: attn_output [B, L, hidden_size] (from attention)
# No normalization needed!

# Q/K/V projections
XQ, XK, XV = self.get_qkv_projections(hidden_states)  # [B, L, num_heads * head_dim]
XQ = XQ.reshape(B, L, num_heads, head_dim).transpose(1, 2)  # [B, num_heads, L, head_dim]

# Batch-parallel TTT (all tokens optimize simultaneously)
W1_init = self.W1.unsqueeze(0).expand(B, -1, -1, -1)  # [B, num_heads, head_dim, head_dim]
b1_init = self.b1.unsqueeze(0).expand(B, -1, -1, -1)  # [B, num_heads, 1, head_dim]

# Compute input-dependent learning rate
ttt_lr = torch.einsum("blc,hci->bhli", hidden_states, self.learnable_ttt_lr_weight)
ttt_lr = ttt_lr + self.learnable_ttt_lr_bias.reshape(1, -1, 1, 1)
ttt_lr = torch.sigmoid(ttt_lr)  # [B, num_heads, L, 1], range (0, 1)
eta = self.ttt_base_lr * ttt_lr / head_dim

# TTT optimization (dual form - closed-form solution)
reconstruction_target = XV - XK
grad_l_wrt_Z1 = ln_fused_l2_bwd(Z1, reconstruction_target, ln_weight, ln_bias)
Attn1 = XQ @ XK.transpose(-2, -1)  # Non-causal: full attention matrix (no tril)
b1_bar = b1_init - (eta * grad_l_wrt_Z1).sum(dim=2, keepdim=True)
Z1_bar = XQ @ W1_init - Attn1 @ (eta * grad_l_wrt_Z1) + b1_bar

# Output
Z1_normalized = ln_fwd(Z1_bar, ln_weight, ln_bias)
output = XQ + Z1_normalized  # Residual

# Post-processing
output = self.post_norm(output)
output = self.o_proj(output)

# Static learnable gating
gating_alpha = torch.tanh(self.gating_alpha)  # [hidden_size], init at 0.1
return output, gating_alpha
```

### ä½¿ç”¨æ–¹å¼ (in modeling_gemma.py)

```python
# TTT receives attention output (no norm)
ttt_output, gate_ttt = self.ttt_layer(attn_output, adarms_cond=None)

# Apply static learnable gate
hidden_states = hidden_states + gate_ttt * ttt_output
```

---

## ğŸ“ å¾…åŠäº‹é¡¹å’Œæœªæ¥æ”¹è¿›

### çŸ­æœŸ (1-2å‘¨)

- [ ] **å®ç° TTTMLP å˜ä½“**
  - åˆ›å»º `TTTMLPWithAdaptiveNorm` ç±»
  - 2-layer MLP: `Z = W2 @ GELU(W1 @ X + b1) + b2`
  - æ·»åŠ  `ttt_layer_type` é…ç½®é€‰é¡¹

- [ ] **æ·»åŠ  `@torch.compile`**
  - `ttt_batch_parallel` æ–¹æ³•
  - `get_qkv_projections` æ–¹æ³•

- [ ] **Reconstruction target normalization**
  - æ·»åŠ  LayerNorm åˆ° `reconstruction_target = XV - XK`

- [ ] **è®­ç»ƒå’ŒéªŒè¯**
  - Debug è®­ç»ƒè·‘é€š
  - ç›‘æ§ TTT gate çš„å­¦ä¹ æƒ…å†µ
  - å¯¹æ¯”æœ‰æ—  TTT çš„æ•ˆæœ

### ä¸­æœŸ (1-2æœˆ)

- [ ] **Bidirectional TTT**
  - Forward + Reverse passes
  - åŒ gate æœºåˆ¶
  - æ¶ˆèå®éªŒ

- [ ] **L2 Normalization on Q/K**
  - æ·»åŠ åˆ° projection ä¹‹å
  - ç›‘æ§è®­ç»ƒç¨³å®šæ€§

- [ ] **æ€§èƒ½ä¼˜åŒ–**
  - Gradient checkpointing
  - Mixed precision ä¼˜åŒ–
  - å†…å­˜ profiling

### é•¿æœŸ (3-6æœˆ)

- [ ] **Triton kernels** (å¦‚æœæˆä¸ºç“¶é¢ˆ)
- [ ] **å¤šæ¨¡æ€ TTT** (æ‰©å±•åˆ° vision encoder)
- [ ] **è‡ªé€‚åº”å±‚é€‰æ‹©** (åŠ¨æ€å†³å®šå“ªäº›å±‚ç”¨ TTT)

---

## ğŸ¯ è®¾è®¡å†³ç­–è®°å½•

### 1. Batch-Parallel vs Sequential Scan

**é€‰æ‹©**: Batch-parallel
**ç†ç”±**:
- Action sequences è¾ƒçŸ­ï¼ˆ256 tokensï¼‰
- æ— éœ€è·¨ mini-batch çš„çŠ¶æ€ä¼ é€’
- æ›´å¿«çš„å¹¶è¡Œè®¡ç®—

### 2. Dual Form vs Primal Form

**é€‰æ‹©**: Dual form (closed-form)
**ç†ç”±**:
- ä¸€æ­¥é—­å¼è§£ï¼Œæ— éœ€è¿­ä»£ä¼˜åŒ–
- æ›´é«˜æ•ˆï¼ˆé¿å…æ˜¾å¼è®¡ç®— `grad_W1`ï¼‰
- æ”¯æŒ learnable input-dependent LRï¼ˆé€šè¿‡ `eta * grad`ï¼‰

### 3. ç§»é™¤ Input Normalization

**ç†ç”±**:
- TTT è¾“å…¥æ˜¯ `attn_output`ï¼Œå·²ç»æ˜¯è‰¯å¥½çš„è¡¨ç¤º
- é¿å…é‡å¤ normalization
- ä¸ ttt-video-dit è®¾è®¡ä¸€è‡´

### 4. Static Learnable Gating

**é€‰æ‹©**: `gating_alpha = nn.Parameter(torch.ones(hidden_size) * 0.1)`
**ç†ç”±**:
- ä¸ ttt-video-dit SSMGating ä¸€è‡´
- åˆå§‹åŒ–ä¸º 0.1ï¼Œè®­ç»ƒä¸­è‡ªé€‚åº”è°ƒæ•´
- Per-dimension æ§åˆ¶ï¼ˆä¸æ˜¯ scalarï¼‰

### 5. AdaRMS Gate (å¯é€‰ï¼Œæœªå¯ç”¨)

**ä¿ç•™ä½†ä¸ä½¿ç”¨**:
- å·²æœ‰å¤–å±‚ AdaRMS gateï¼ˆåœ¨ `input_layernorm`ï¼‰
- ä¿ç•™æ¥å£ä¾›æœªæ¥å®éªŒ
- ç›®å‰åªç”¨é™æ€ `gating_alpha`

### 6. Non-Causal Attention (å»é™¤å› æœæ©ç )

**é€‰æ‹©**: å»é™¤ `torch.tril`ï¼Œä½¿ç”¨å®Œæ•´ attention matrix
**ç†ç”±**:
- å»å™ªä»»åŠ¡ä¸­æ‰€æœ‰ tokens åŒæ—¶å¯è§ï¼Œæ— å› æœä¾èµ–
- å…è®¸æ¯ä¸ª token åˆ©ç”¨æ•´ä¸ªåºåˆ—ä¿¡æ¯
- ä¸æ ‡å‡† DiT self-attention å¯¹é½

### 7. Input-Dependent Learning Rate

**é€‰æ‹©**: `eta = ttt_base_lr * sigmoid(X @ W_lr + b_lr) / head_dim`
**ç†ç”±**:
- è®©å­¦ä¹ ç‡é€‚åº”ä¸åŒè¾“å…¥ç‰¹å¾
- ä¿ç•™åŸå§‹ ttt.py ä¸­ `ttt_lr_eta` çš„è®¾è®¡æ€æƒ³
- å»æ‰ `token_eta`ï¼ˆä½ç½®æƒé‡ï¼‰ï¼Œå› ä¸ºéå› æœä»»åŠ¡ä¸­æ‰€æœ‰ token å¹³ç­‰

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

### å†…éƒ¨æ–‡æ¡£
- `/opt/tiger/openpi/ttt_video_dit_comparison.md` - ttt-video-dit å¯¹æ¯”åˆ†æ
- `/opt/tiger/openpi/ttt-video-dit/` - å‚è€ƒå®ç°

### å¤–éƒ¨èµ„æº
- [TTT Paper](https://arxiv.org/abs/2407.04620) - Test-Time Training layers
- [ttt-video-dit repo](https://test-time-training.github.io/video-dit/) - Video generation with TTT
- [CogVideoX](https://github.com/THUDM/CogVideo) - Base architecture

---

## ğŸ› å·²çŸ¥é—®é¢˜

### å½“å‰æ— å·²çŸ¥é—®é¢˜ âœ…

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡† (å¾…æµ‹è¯•)

### é¢„æœŸæå‡
- **é•¿åºåˆ—å»ºæ¨¡**: æ›´å¥½å¤„ç† 256 token çš„ action sequences
- **å»å™ªè´¨é‡**: TTT è‡ªé€‚åº”ä¼˜åŒ–æå‡åŠ¨ä½œé¢„æµ‹
- **è®­ç»ƒç¨³å®šæ€§**: Learnable gating è‡ªåŠ¨è°ƒæ•´ TTT è´¡çŒ®

### å¾…æµ‹é‡æŒ‡æ ‡
- [ ] Loss curves (with vs without TTT)
- [ ] Action prediction accuracy
- [ ] Training time overhead
- [ ] Memory usage
- [ ] Gate values distribution

---

**æœ€åæ›´æ–°**: 2025-10-10
**çŠ¶æ€**: Phase 1 & 2 & 3 å®Œæˆï¼Œå¾…è®­ç»ƒéªŒè¯
**ä¸‹ä¸€æ­¥**: è®­ç»ƒæµ‹è¯• + å¯é€‰å®ç° TTTMLP å˜ä½“

---

## ğŸ†• Phase 3 æ›´æ–° (2025-10-10)

### æ ¸å¿ƒæ”¹è¿›ï¼šNon-Causal + Input-Dependent Learning Rate

**åŠ¨æœº**:
åŸå§‹ TTT å®ç°ä¸ºè¯­è¨€å»ºæ¨¡è®¾è®¡ï¼ˆå› æœä¾èµ–ï¼‰ï¼Œä½† diffusion å»å™ªä»»åŠ¡ä¸­æ‰€æœ‰ tokens åº”åŒæ—¶å¯è§ã€‚åŒæ—¶ï¼Œå›ºå®šå­¦ä¹ ç‡æ— æ³•é€‚åº”ä¸åŒè¾“å…¥ç‰¹å¾ã€‚

**å…³é”®å˜æ›´**:
1. **å»é™¤å› æœæ©ç **: `Attn1 = XQ @ X1.transpose(-2, -1)` (no `torch.tril`)
2. **å¯å­¦ä¹  LR**: `eta = ttt_base_lr * sigmoid(X @ W_lr + b_lr) / head_dim` [B, num_heads, L, 1]
3. **å»æ‰ token_eta**: ä¸å†ä½¿ç”¨ä½ç½®ç›¸å…³çš„é€’å‡æƒé‡ï¼ˆæ‰€æœ‰ token å¹³ç­‰ï¼‰

**å‚æ•°å¢åŠ **:
- `learnable_ttt_lr_weight`: [num_heads, hidden_size, 1]
- `learnable_ttt_lr_bias`: [num_heads, 1]

**ä¸åŸå§‹ ttt.py å¯¹æ¯”**:

| é¡¹ç›® | åŸå§‹ ttt.py | OpenPI TTT |
|------|-------------|------------|
| å› æœæ©ç  | âœ… `torch.tril` | âŒ å»é™¤ |
| token_eta | âœ… `[1.0, 0.5, 0.33, ...]` | âŒ å»é™¤ |
| ttt_lr_eta | âœ… å¯å­¦ä¹  | âœ… å¯å­¦ä¹  |
| eta ç»„åˆ | `token_eta * ttt_lr_eta` | `ttt_lr_eta` only |
| é€‚ç”¨åœºæ™¯ | å› æœè¯­è¨€å»ºæ¨¡ | éå› æœå»å™ª |

**æµ‹è¯•ç»“æœ**: âœ… æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ï¼ˆ4/4ï¼‰
